{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Distributed Computing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import dill\n",
    "import time\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "sys.path.append('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create list of packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 https://github.com/onurakpolat/awesome-bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = requests.get('https://github.com/onurakpolat/awesome-bigdata')\n",
    "soup1 = BeautifulSoup(r1.text, 'lxml')\n",
    "pkgs1 = []\n",
    "for ana in soup1.findAll('a', attrs={'span class': None}):\n",
    "    if ana.parent.name == 'li':       \n",
    "        pkgs1.append(str(ana.text).lower().strip())\n",
    "pkgs1 = pkgs1[55:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ibm streams', 'apache hadoop', 'tigon', 'pachyderm', 'addthis hydra', 'amplab simr', 'apache apex', 'apache beam', 'apache crunch', 'apache datafu', 'apache flink', 'apache gearpump', 'apache gora', 'apache hama', 'apache mapreduce', 'apache pig', 'apache reef', 'apache s4', 'apache spark', 'apache spark streaming', 'apache storm', 'apache samza', 'apache tez', 'apache twill', 'cascalog', 'cheetah', 'concurrent cascading', 'damballa parkour', 'datasalt pangool', 'datatorrent stram', 'facebook corona', 'facebook peregrine', 'facebook scuba', 'google dataflow', 'google mapreduce', 'google millwheel', 'ibm streams', 'jaql', 'kite', 'metamarkets druid', 'netflix pigpen', 'nokia disco', 'onyx', 'pinterest pinlater', 'pydoop', 'rackerlabs blueflood', 'skale', 'stratosphere', 'streamdrill', 'streamsx.topology', 'tuktu', 'twitter heron', 'twitter scalding', 'twitter summingbird', 'twitter tsar']\n"
     ]
    }
   ],
   "source": [
    "print pkgs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 https://projects.apache.org/projects.html?category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.set_page_load_timeout(20)\n",
    "url = \"https://projects.apache.org/projects.html?category\"\n",
    "driver.get(url)\n",
    "time.sleep(20)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projects = []\n",
    "for ana in soup.findAll('a'):\n",
    "    if ana.parent.name == 'li':       \n",
    "        projects.append(unicodedata.normalize('NFKD', ana.text).encode('ascii','ignore').lower().strip())\n",
    "pkgs2 = projects[12:50] #only took projects in BigData Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkgs2 = [pkg.replace('(incubating)','').strip() for pkg in pkgs2]\n",
    "# remove \"incubating\" from names\n",
    "\n",
    "pkgs2.remove('apache directmemory (in the attic)')\n",
    "#remove retired project  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache airavata', 'apache ambari', 'apache apex', 'apache avro', 'apache beam', 'apache bigtop', 'apache bookkeeper', 'apache calcite', 'apache couchdb', 'apache crunch', 'apache datafu', 'apache drill', 'apache edgent', 'apache falcon', 'apache flink', 'apache flume', 'apache giraph', 'apache hama', 'apache helix', 'apache ignite', 'apache kafka', 'apache knox', 'apache lens', 'apache metamodel', 'apache oozie', 'apache orc', 'apache parquet', 'apache phoenix', 'apache reef', 'apache samza', 'apache spark', 'apache sqoop', 'apache storm', 'apache tajo', 'apache tez', 'apache vxquery', 'apache zeppelin']\n"
     ]
    }
   ],
   "source": [
    "print pkgs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 http://analyticsindiamag.com/10-hadoop-alternatives-consider-big-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r3 = requests.get('http://analyticsindiamag.com/10-hadoop-alternatives-consider-big-data/')\n",
    "soup3 = BeautifulSoup(r3.text, 'lxml')\n",
    "pkgs3 = []\n",
    "for ana in soup3.findAll('a'):\n",
    "    if ana.parent.name == 'h1':       \n",
    "        pkgs3.append(unicodedata.normalize('NFKD', ana.text).encode('ascii','ignore').lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache spark', 'apache storm', 'ceph', 'datatorrent rts', 'disco', 'google bigquery', 'high-performance computing cluster (hpcc)', 'hydra', 'pachyderm', 'presto']\n"
     ]
    }
   ],
   "source": [
    "print pkgs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 http://bigdata.andreamostosi.name/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r4 = requests.get('http://bigdata.andreamostosi.name/')\n",
    "soup4 = BeautifulSoup(r4.text, 'lxml')\n",
    "pkgs4 = []\n",
    "for ana in soup4.findAll('td'):\n",
    "    if '\\n' not in ana.text:\n",
    "        pkgs4.append(unicodedata.normalize('NFKD', ana.text).encode('ascii','ignore').lower().strip())\n",
    "pkgs4 = pkgs4[:101]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache hadoop', 'addthis hydra', 'akela', 'amazon lambda', 'amazon spice', 'ampcrowd', 'amplab g-ola', 'amplab simr', 'apache crunch', 'apache datafu', 'apache flink', 'apache gora', 'apache hama', 'apache ignite', 'apache mapreduce', 'apache pig', 'apache s4', 'apache spark', 'apache spark streaming', 'apache storm', 'apache tez', 'apache twill', 'arvados', 'blaze', 'cascalog', 'cheetah', 'concurrent cascading', 'damballa parkour', 'datasalt pangool', 'datatorrent stram', 'distributedr', 'drools', 'ebay oink', 'esper', 'facebook corona', 'facebook peregrine', 'facebook scuba', 'gearpump', 'geotrellis', 'getstream stream framework', 'gis tools for hadoop', 'google dataflow', 'google flumejava', 'google mapreduce', 'google millwheel', 'graphlab dato', 'hazelcast', 'hparser', 'ibm streams', 'jaql', 'kite', 'kryo', 'linkedin cubert', 'lipstick', 'metamarkers druid', 'microsoft azure stream analytics', 'microsoft orleans', 'microsoft project orleans', 'microsoft trill', 'netflix aegisthus', 'netflix lipstick', 'netflix mantis', 'netflix pigpen', 'netflix staash', 'netflix surus', 'netflix zeno', 'nextflow', 'nokia disco', 'oryx', 'pachyderm', 'parsely streamparse', 'pigpen', 'pinterest pinlater', 'pubnub', 'pydoop', 'scaleout hserver', 'seqpig', 'sigmoidanalytics spork', 'snap', 'spark-dataflow', 'spatialhadoop', 'spring for apache hadoop', 'sqlstream blaze', 'stratio crossdata', 'stratio decision', 'stratio streaming', 'stratosphere', 'streamdrill', 'succinct spark', 'sumo logic', 'teradata querygrid', 'tibco activespaces', 'tigon', 'torch', 'trident', 'twitter crane', 'twitter gizzard', 'twitter heron', 'twitter scalding', 'twitter summingbird', 'twitter tsar']\n"
     ]
    }
   ],
   "source": [
    "print pkgs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkgs = list(set(pkgs1 + pkgs2 + pkgs3 + pkgs4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pkgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkgs.remove('pigpen')\n",
    "#remove pigpen, same as netflix pigpen\n",
    "pkgs.remove('lipstick')\n",
    "#same as netflix lipstick\n",
    "pkgs.remove('stratosphere')\n",
    "#now apache flink\n",
    "pkgs.remove('hydra')\n",
    "#same as addthis hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache storm', 'stratio crossdata', 'kite', 'twitter gizzard', 'apache knox', 'apache reef', 'apache tajo', 'pachyderm', 'nextflow', 'apache sqoop', 'apache metamodel', 'apache vxquery', 'cascalog', 'parsely streamparse', 'datasalt pangool', 'apache parquet', 'succinct spark', 'blaze', 'netflix staash', 'skale', 'metamarkets druid', 'distributedr', 'twitter tsar', 'sigmoidanalytics spork', 'apache ambari', 'amplab simr', 'apache calcite', 'stratio streaming', 'apache gora', 'apache helix', 'apache edgent', 'disco', 'ebay oink', 'rackerlabs blueflood', 'torch', 'pinterest pinlater', 'google mapreduce', 'apache twill', 'google dataflow', 'apache mapreduce', 'apache bigtop', 'apache bookkeeper', 'hazelcast', 'apache flume', 'datatorrent stram', 'graphlab dato', 'spatialhadoop', 'gis tools for hadoop', 'twitter crane', 'drools', 'gearpump', 'apache falcon', 'kryo', 'apache ignite', 'sqlstream blaze', 'twitter summingbird', 'arvados', 'apache giraph', 'netflix aegisthus', 'apache apex', 'netflix mantis', 'google flumejava', 'google millwheel', 'apache pig', 'metamarkers druid', 'twitter scalding', 'apache beam', 'twitter heron', 'netflix zeno', 'microsoft trill', 'tibco activespaces', 'pubnub', 'ampcrowd', 'microsoft project orleans', 'apache samza', 'amazon lambda', 'seqpig', 'oryx', 'high-performance computing cluster (hpcc)', 'amplab g-ola', 'netflix lipstick', 'ibm streams', 'apache spark streaming', 'teradata querygrid', 'onyx', 'apache spark', 'snap', 'google bigquery', 'apache couchdb', 'nokia disco', 'apache phoenix', 'apache kafka', 'apache drill', 'netflix surus', 'apache s4', 'netflix pigpen', 'hparser', 'spring for apache hadoop', 'facebook scuba', 'streamsx.topology', 'apache flink', 'apache airavata', 'apache zeppelin', 'apache gearpump', 'tuktu', 'datatorrent rts', 'ceph', 'linkedin cubert', 'amazon spice', 'spark-dataflow', 'apache datafu', 'damballa parkour', 'microsoft azure stream analytics', 'esper', 'scaleout hserver', 'akela', 'getstream stream framework', 'cheetah', 'facebook corona', 'addthis hydra', 'trident', 'geotrellis', 'apache hadoop', 'facebook peregrine', 'apache avro', 'apache oozie', 'concurrent cascading', 'stratio decision', 'pydoop', 'presto', 'jaql', 'apache lens', 'apache tez', 'apache hama', 'streamdrill', 'sumo logic', 'apache orc', 'microsoft orleans', 'apache crunch', 'tigon']\n"
     ]
    }
   ],
   "source": [
    "print pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pkgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## github stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../code/secrets/github-token.nogit\", \"rb\") as f:\n",
    "    token = f.read()\n",
    "\n",
    "headers = {'Authorization': 'token %s' % token}\n",
    "\n",
    "def get_data_from_search(query):\n",
    "    \"\"\"Use github search to return stars, forks for top query result\"\"\"\n",
    "    r = requests.get('https://api.github.com/search/repositories?q='+\\\n",
    "                             query, \n",
    "                     headers=headers)\n",
    "    r.raise_for_status()\n",
    "    try:\n",
    "        res = r.json()['items'][0]\n",
    "        return {'package': query, 'full_name': res['full_name'],\n",
    "                'stars': res['stargazers_count'], 'forks': res['forks_count']}\n",
    "    except:\n",
    "        return {'package': query, 'full_name': 'NA',\n",
    "                'stars': 0, 'forks': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use generator to avoid repeat API calls; API limit with token: 30 api calls/min\n",
    "github_data = []\n",
    "for ii in range(int(len(pkgs)/20)):\n",
    "    start = ii*20\n",
    "    end = int(ii+1)*20\n",
    "    data = [res for res in (get_data_from_search(query) for query in pkgs[start:end]) if res is not None]\n",
    "    github_data.extend(data)\n",
    "    time.sleep(61) \n",
    "data = [res for res in (get_data_from_search(query) for query in pkgs[end:]) if res is not None]\n",
    "github_data.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "github = pd.DataFrame(github_data)[['package', 'full_name', 'forks', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## github search doesn't always return the correct repo. function to replace repos and stats\n",
    "def replace_repo_stats(package, repo_address):\n",
    "    r = requests.get('https://api.github.com/repos/'+repo_address, headers=headers)\n",
    "    res = r.json()\n",
    "    github.loc[github['package'] == package, 'full_name'] = repo_address\n",
    "    github.loc[github['package'] == package, 'forks'] = res['forks_count']\n",
    "    github.loc[github['package'] == package, 'stars'] = res['stargazers_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_repos = [('addthis hydra','addthis/hydra'),\n",
    "              ('stratio crossdata','Stratio/crossdata'),\n",
    "              ('twitter gizzard','twitter-archive/gizzard'),\n",
    "              ('concurrent cascading', 'cwensel/cascading'), \n",
    "              ('datasalt pangool', 'datasalt/pangool'),\n",
    "              ('netflix staash','Netflix/staash'),\n",
    "              ('metamarkets druid','druid-io/druid'),\n",
    "              ('sigmoidanalytics spork', 'sigmoidanalytics/spork'),\n",
    "              ('ebay oink', 'eBay/oink'),\n",
    "              ('rackerlabs blueflood', 'rackerlabs/blueflood'),\n",
    "              ('apache mapreduce','apache/hadoop-mapreduce'),\n",
    "              ('stratio decision', 'Stratio/Decision'),\n",
    "              ('netflix aegisthus', 'Netflix/aegisthus'),\n",
    "              ('twitter scalding', 'twitter/scalding'),\n",
    "              ('twitter summingbird','twitter/summingbird'),\n",
    "              ('netflix lipstick', 'Netflix/Lipstick'),\n",
    "              ('nokia disco', 'discoproject/disco'),\n",
    "              ('netflix surus', 'Netflix/Surus'),\n",
    "              ('netflix pigpen', 'Netflix/PigPen'),\n",
    "              ('linkedin cubert', 'linkedin/Cubert'),\n",
    "              ('damballa parkour', 'damballa/parkour'),\n",
    "              ('getstream stream framework', 'tschellenbach/Stream-Framework'),\n",
    "              ('snap', 'snap-stanford/snap')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (package, r_address) in good_repos:\n",
    "    replace_repo_stats(package, r_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_github_repo = ['twitter crane', 'microsoft azure stream analytics', 'amazon spice', \n",
    "                  'sumo logic', 'graphlab dato', 'ibmstreams','microsoft project orleans', \n",
    "                  'facebook corona', 'amazon lambda', 'google bigquery']\n",
    "\n",
    "##these packages have no real github repos, but searching github returned some incorrect \n",
    "##results, so they are manually changed to 0 forks and 0 stars\n",
    "\n",
    "for pkg in no_github_repo:\n",
    "    github.loc[github['package'] == pkg, 'full_name'] = 'NA'\n",
    "    github.loc[github['package'] == pkg, 'forks'] = 0\n",
    "    github.loc[github['package'] == pkg, 'stars'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "github.to_csv(\"../data/DC_results_github.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>full_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>apache spark</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>13434</td>\n",
       "      <td>14365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>apache kafka</td>\n",
       "      <td>apache/kafka</td>\n",
       "      <td>3776</td>\n",
       "      <td>6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>apache hadoop</td>\n",
       "      <td>apache/hadoop</td>\n",
       "      <td>3476</td>\n",
       "      <td>3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache storm</td>\n",
       "      <td>apache/storm</td>\n",
       "      <td>3314</td>\n",
       "      <td>4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>presto</td>\n",
       "      <td>prestodb/presto</td>\n",
       "      <td>2131</td>\n",
       "      <td>6482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ceph</td>\n",
       "      <td>ceph/ceph</td>\n",
       "      <td>2092</td>\n",
       "      <td>3627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>apache flink</td>\n",
       "      <td>apache/flink</td>\n",
       "      <td>1872</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>apache zeppelin</td>\n",
       "      <td>apache/zeppelin</td>\n",
       "      <td>1593</td>\n",
       "      <td>3122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>metamarkets druid</td>\n",
       "      <td>druid-io/druid</td>\n",
       "      <td>1326</td>\n",
       "      <td>5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>drools</td>\n",
       "      <td>kiegroup/drools</td>\n",
       "      <td>1187</td>\n",
       "      <td>1087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               package        full_name  forks  stars\n",
       "85        apache spark     apache/spark  13434  14365\n",
       "91        apache kafka     apache/kafka   3776   6157\n",
       "122      apache hadoop    apache/hadoop   3476   3754\n",
       "0         apache storm     apache/storm   3314   4496\n",
       "129             presto  prestodb/presto   2131   6482\n",
       "106               ceph        ceph/ceph   2092   3627\n",
       "100       apache flink     apache/flink   1872   2709\n",
       "102    apache zeppelin  apache/zeppelin   1593   3122\n",
       "20   metamarkets druid   druid-io/druid   1326   5443\n",
       "49              drools  kiegroup/drools   1187   1087"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github.sort_values(['forks'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get StackOverflow Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseurl = 'https://api.stackexchange.com/2.2/search/advanced'\n",
    "\n",
    "def get_so_stats(package, tag):\n",
    "#Given tag, return tag counts, and count of questions countaining the tag name\n",
    "    params = {\n",
    "    \"site\": \"stackoverflow\",\n",
    "    \"key\": \"y38PeNERQJQIC8EPliKAVQ((\",\n",
    "    \"tagged\": tag,  \n",
    "    \"filter\": 'total'}\n",
    "    try:\n",
    "        r1 = requests.get(baseurl, params=params)\n",
    "        so_tag_counts = r1.json()['total']\n",
    "    except:\n",
    "        so_tag_counts = 0\n",
    "    params = {\n",
    "    \"site\": \"stackoverflow\",\n",
    "    \"key\": \"y38PeNERQJQIC8EPliKAVQ((\",\n",
    "    \"q\": tag,  \n",
    "    \"filter\": \"total\"}\n",
    "    try:\n",
    "        r = requests.get(baseurl, params=params)\n",
    "        return {'package':package, 'so_alias': tag,'so_tag_count': so_tag_counts, 'so_question_count': r.json()['total']}\n",
    "    except:\n",
    "        return {'package':package, 'so_alias': tag,'so_tag_count': so_tag_counts, 'so_question_count': 0}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = [pkg.replace(' ','-') for pkg in pkgs]\n",
    "pkg_tag = zip(pkgs,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so_data = []\n",
    "for (package, tag) in pkg_tag:\n",
    "    so_data.append(get_so_stats(package, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so_DF = pd.DataFrame(so_data)[['package','so_alias', 'so_tag_count', 'so_question_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## manually change some of the package tags to match SO tag database\n",
    "def replace_tag_stats(package, tag):\n",
    "    res = get_so_stats(package, tag)\n",
    "    so_DF.loc[so_DF['package'] == package, 'so_alias'] = tag\n",
    "    so_DF.loc[so_DF['package'] == package, 'so_tag_count'] = res['so_tag_count']\n",
    "    so_DF.loc[so_DF['package'] == package, 'so_question_count'] = res['so_question_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "so_tags = [('apache spark streaming', 'spark-streaming'),\n",
    "           ('apache orc', 'orc'),\n",
    "           ('sumo logic', 'sumologic'),\n",
    "           ('microsoft azure stream analytics', 'azure-stream-analytics'),\n",
    "           ('apache flume', 'flume'),\n",
    "           ('parsely streamparse', 'streamparse'),\n",
    "           ('metamarkets druid', 'druid'),\n",
    "           ('apache gora', 'gora'),\n",
    "           ('apache hadoop', 'hadoop'),\n",
    "           ('snap', 'stanford-snap'),\n",
    "           ('nokia disco', 'disco'),\n",
    "           ('concurrent cascading', 'cascading'),\n",
    "           ('apache hama', 'hama'),\n",
    "           ('apache ignite', 'ignite'),\n",
    "           ('twitter scalding', 'scalding'),  \n",
    "           ('apache parquet', 'parquet'),\n",
    "           ('apache giraph', 'giraph'),\n",
    "           ('apache knox', 'knox-gateway'),\n",
    "           ('apache calcite', 'calcite'),\n",
    "           ('apache hbase','hbase'),\n",
    "           ('spot','spotify-scio'),\n",
    "           ('apache avro', 'avro'),\n",
    "           ('apache oozie', 'oozie'),\n",
    "           ('apache ambari','ambari'),\n",
    "           ('apache phoenix','pheonix'),\n",
    "           ('apache couchdb', 'couchdb'),\n",
    "           ('apache lucene.net', 'lucene.net'),\n",
    "           ('toree', 'apache-toree'),\n",
    "           ('apache bigtop', 'bigtop'),\n",
    "           ('high-performance computing cluster (hpcc)', 'hpcc'),\n",
    "           ('presto', 'prestodb')]\n",
    "\n",
    "for (package, tag) in so_tags:\n",
    "    replace_tag_stats(package, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>so_alias</th>\n",
       "      <th>so_tag_count</th>\n",
       "      <th>so_question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>apache hadoop</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>35431</td>\n",
       "      <td>41804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>apache spark</td>\n",
       "      <td>apache-spark</td>\n",
       "      <td>31460</td>\n",
       "      <td>32329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>apache kafka</td>\n",
       "      <td>apache-kafka</td>\n",
       "      <td>6232</td>\n",
       "      <td>6607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>google bigquery</td>\n",
       "      <td>google-bigquery</td>\n",
       "      <td>5428</td>\n",
       "      <td>5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>apache couchdb</td>\n",
       "      <td>couchdb</td>\n",
       "      <td>4972</td>\n",
       "      <td>6397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             package         so_alias  so_tag_count  so_question_count\n",
       "122    apache hadoop           hadoop         35431              41804\n",
       "85      apache spark     apache-spark         31460              32329\n",
       "91      apache kafka     apache-kafka          6232               6607\n",
       "87   google bigquery  google-bigquery          5428               5714\n",
       "88    apache couchdb          couchdb          4972               6397"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so_DF.sort_values(['so_tag_count'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so_DF.to_csv(\"../data/DC_pkgs_results_stackoverflow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Google Search Results Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../code/secrets/google_token.nogit\", \"rb\") as f:\n",
    "    my_api_key = f.read()\n",
    "    \n",
    "with open(\"../code/secrets/cse_token.nogit\", \"rb\") as f:\n",
    "    my_cse_id = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def google_search_stats(package, search_term, api_key, cse_id):\n",
    "    search_term = search_term.replace(' ','+')\n",
    "    r= requests.get('https://www.googleapis.com/customsearch/v1?q=\"'+search_term+'\"&alt=json&cx='\n",
    "                    +cse_id+'&c2coff=1&dateRestrict=y5&rc=1&key='\n",
    "                    +api_key)\n",
    "    res = r.json()['queries']['request'][0]\n",
    "    search_results = int(res['totalResults'])\n",
    "\n",
    "    ##get count for last 6 months--- dateRestrict=m6\n",
    "    r= requests.get('https://www.googleapis.com/customsearch/v1?q=\"'+search_term+\n",
    "                    '\"&alt=json&cx='+cse_id+'&c2coff=1&dateRestrict=m6&rc=1&key='+api_key)\n",
    "    res = r.json()['queries']['request'][0]\n",
    "    six_months = int(res['totalResults'])\n",
    "    \n",
    "    ##get count for last 3 months--- dateRestrict=m3    \n",
    "    r= requests.get('https://www.googleapis.com/customsearch/v1?q=\"'+search_term+\n",
    "                    '\"&alt=json&cx='+cse_id+'&c2coff=1&dateRestrict=m3&rc=1&key='+api_key)\n",
    "    res = r.json()['queries']['request'][0]\n",
    "    current_quarter = int(res['totalResults'])    \n",
    "    last_quarter = six_months - current_quarter\n",
    "    if last_quarter < 1:\n",
    "        growth_rate = np.NaN\n",
    "    else:\n",
    "        growth_rate = (float(current_quarter)-float(last_quarter))/float(last_quarter)\n",
    "    return {'package': package, 'search_results': search_results, 'growth_rate': growth_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "google_data = [res for res in (google_search_stats(q, q, my_api_key, my_cse_id) for q in pkgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "googleDF = pd.DataFrame(google_data)[['package', 'search_results', 'growth_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## some packages have very common names (ie, snap and kite) more specific search terms were used for google\n",
    "def replace_google_stats(package, alias):\n",
    "    res = google_search_stats(package, alias, my_api_key, my_cse_id)\n",
    "    googleDF.loc[googleDF['package'] == package, 'search_results'] = res['search_results']\n",
    "    googleDF.loc[googleDF['package'] == package, 'growth_rate'] = res['growth_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_search_terms = [('kite', 'kite API'),\n",
    "                     ('skale', 'skale engine'),\n",
    "                     ('oryx', 'oryx framework'),\n",
    "                     ('akela', 'mozilla akela'),\n",
    "                     ('snap', 'snap-stanford'),\n",
    "                     ('blaze', 'blaze python'),\n",
    "                     ('pachyderm', 'pachyderm pipeline'),\n",
    "                     ('presto', 'prestodb'),\n",
    "                     ('drools', 'drools 5'),\n",
    "                     ('gearpump', 'apache gearpump'),\n",
    "                     ('ceph', 'ceph platform'),\n",
    "                     ('onyx', 'onyx platform'),\n",
    "                     ('kryo', 'esoteric software kryo'),\n",
    "                     ('tigon', 'cask data tigon'),\n",
    "                     ('torch', 'torch7'),\n",
    "                    ('cheetah', 'cheetah engine'),\n",
    "                    ('trident', 'apache trident'),\n",
    "                    ('esper', 'espertech'),\n",
    "                    ('sumo logic', 'sumologic'),\n",
    "                    ('disco', 'discoproject')]\n",
    "for (package, term) in good_search_terms:\n",
    "    replace_google_stats(package, term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>search_results</th>\n",
       "      <th>growth_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stratio crossdata</td>\n",
       "      <td>83</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>apache bookkeeper</td>\n",
       "      <td>601</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apache vxquery</td>\n",
       "      <td>1120</td>\n",
       "      <td>2.347561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>hparser</td>\n",
       "      <td>665</td>\n",
       "      <td>1.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>twitter heron</td>\n",
       "      <td>1210</td>\n",
       "      <td>1.797980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              package  search_results  growth_rate\n",
       "1   stratio crossdata              83     4.000000\n",
       "41  apache bookkeeper             601     2.666667\n",
       "11     apache vxquery            1120     2.347561\n",
       "96            hparser             665     1.933333\n",
       "67      twitter heron            1210     1.797980"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googleDF.sort_values(['growth_rate'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>search_results</th>\n",
       "      <th>growth_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>apache spark</td>\n",
       "      <td>261000</td>\n",
       "      <td>0.349057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>apache hadoop</td>\n",
       "      <td>192000</td>\n",
       "      <td>0.053892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>apache kafka</td>\n",
       "      <td>84300</td>\n",
       "      <td>0.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache storm</td>\n",
       "      <td>44000</td>\n",
       "      <td>-0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>apache pig</td>\n",
       "      <td>34100</td>\n",
       "      <td>-0.436807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>apache flume</td>\n",
       "      <td>29900</td>\n",
       "      <td>0.242744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>apache spark streaming</td>\n",
       "      <td>25400</td>\n",
       "      <td>0.197740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>google bigquery</td>\n",
       "      <td>24300</td>\n",
       "      <td>0.382184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hazelcast</td>\n",
       "      <td>23800</td>\n",
       "      <td>0.639405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>apache flink</td>\n",
       "      <td>18200</td>\n",
       "      <td>0.789272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pubnub</td>\n",
       "      <td>14000</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>apache drill</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.770992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>torch</td>\n",
       "      <td>9090</td>\n",
       "      <td>-0.097902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>apache zeppelin</td>\n",
       "      <td>7750</td>\n",
       "      <td>-0.125926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>apache phoenix</td>\n",
       "      <td>7420</td>\n",
       "      <td>0.082569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apache ambari</td>\n",
       "      <td>7240</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>apache ignite</td>\n",
       "      <td>7080</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sumo logic</td>\n",
       "      <td>7050</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apache sqoop</td>\n",
       "      <td>6740</td>\n",
       "      <td>-0.108776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>presto</td>\n",
       "      <td>6700</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>apache avro</td>\n",
       "      <td>6230</td>\n",
       "      <td>-0.073770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>apache beam</td>\n",
       "      <td>5490</td>\n",
       "      <td>-0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>apache couchdb</td>\n",
       "      <td>5430</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>amazon lambda</td>\n",
       "      <td>5360</td>\n",
       "      <td>0.186916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>apache oozie</td>\n",
       "      <td>5230</td>\n",
       "      <td>-0.138801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>jaql</td>\n",
       "      <td>5140</td>\n",
       "      <td>0.045061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tuktu</td>\n",
       "      <td>4820</td>\n",
       "      <td>-0.045113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>microsoft azure stream analytics</td>\n",
       "      <td>4420</td>\n",
       "      <td>-0.125677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>snap</td>\n",
       "      <td>3630</td>\n",
       "      <td>-0.432507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>apache parquet</td>\n",
       "      <td>3510</td>\n",
       "      <td>0.765531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              package  search_results  growth_rate\n",
       "85                       apache spark          261000     0.349057\n",
       "122                     apache hadoop          192000     0.053892\n",
       "91                       apache kafka           84300     0.168000\n",
       "0                        apache storm           44000    -0.205128\n",
       "63                         apache pig           34100    -0.436807\n",
       "43                       apache flume           29900     0.242744\n",
       "82             apache spark streaming           25400     0.197740\n",
       "87                    google bigquery           24300     0.382184\n",
       "42                          hazelcast           23800     0.639405\n",
       "100                      apache flink           18200     0.789272\n",
       "71                             pubnub           14000     0.553571\n",
       "92                       apache drill           12000     0.770992\n",
       "34                              torch            9090    -0.097902\n",
       "102                   apache zeppelin            7750    -0.125926\n",
       "90                     apache phoenix            7420     0.082569\n",
       "24                      apache ambari            7240     0.291667\n",
       "53                      apache ignite            7080     0.780000\n",
       "135                        sumo logic            7050     0.560000\n",
       "9                        apache sqoop            6740    -0.108776\n",
       "129                            presto            6700     0.561224\n",
       "124                       apache avro            6230    -0.073770\n",
       "66                        apache beam            5490    -0.022222\n",
       "88                     apache couchdb            5430     0.190476\n",
       "75                      amazon lambda            5360     0.186916\n",
       "125                      apache oozie            5230    -0.138801\n",
       "130                              jaql            5140     0.045061\n",
       "104                             tuktu            4820    -0.045113\n",
       "112  microsoft azure stream analytics            4420    -0.125677\n",
       "86                               snap            3630    -0.432507\n",
       "15                     apache parquet            3510     0.765531"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googleDF.sort_values(['search_results'],ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "googleDF.to_csv(\"../data/DC_packages_results_google.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcpkgsDF = github.merge(so_DF, on='package', copy = False)\n",
    "dcpkgsDF = dcpkgsDF.merge(googleDF, on='package', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>full_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>stars</th>\n",
       "      <th>so_alias</th>\n",
       "      <th>so_tag_count</th>\n",
       "      <th>so_question_count</th>\n",
       "      <th>search_results</th>\n",
       "      <th>growth_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache storm</td>\n",
       "      <td>apache/storm</td>\n",
       "      <td>3314</td>\n",
       "      <td>4496</td>\n",
       "      <td>apache-storm</td>\n",
       "      <td>2086</td>\n",
       "      <td>2209</td>\n",
       "      <td>44000</td>\n",
       "      <td>-0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stratio crossdata</td>\n",
       "      <td>Stratio/crossdata</td>\n",
       "      <td>40</td>\n",
       "      <td>154</td>\n",
       "      <td>stratio-crossdata</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kite</td>\n",
       "      <td>kite-sdk/kite</td>\n",
       "      <td>203</td>\n",
       "      <td>301</td>\n",
       "      <td>kite</td>\n",
       "      <td>9</td>\n",
       "      <td>330</td>\n",
       "      <td>217</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter gizzard</td>\n",
       "      <td>twitter-archive/gizzard</td>\n",
       "      <td>208</td>\n",
       "      <td>2144</td>\n",
       "      <td>twitter-gizzard</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache knox</td>\n",
       "      <td>apache/knox</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>knox-gateway</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1640</td>\n",
       "      <td>-0.280769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             package                full_name  forks  stars  \\\n",
       "0       apache storm             apache/storm   3314   4496   \n",
       "1  stratio crossdata        Stratio/crossdata     40    154   \n",
       "2               kite            kite-sdk/kite    203    301   \n",
       "3    twitter gizzard  twitter-archive/gizzard    208   2144   \n",
       "4        apache knox              apache/knox     62     37   \n",
       "\n",
       "            so_alias  so_tag_count  so_question_count  search_results  \\\n",
       "0       apache-storm          2086               2209           44000   \n",
       "1  stratio-crossdata             0                  0              83   \n",
       "2               kite             9                330             217   \n",
       "3    twitter-gizzard             0                  4              46   \n",
       "4       knox-gateway            20                 33            1640   \n",
       "\n",
       "   growth_rate  \n",
       "0    -0.205128  \n",
       "1     4.000000  \n",
       "2     0.444444  \n",
       "3    -1.000000  \n",
       "4    -0.280769  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcpkgsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcpkgsDF.to_csv(\"../output/distributed_computing_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
